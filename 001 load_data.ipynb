{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowknow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowknow.datasources import jstor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mjstor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjstor_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mjstor_zip_base\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moutput_database\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'default-database-name'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mname_blacklist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mRUN_EVERYTHING\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcomplex_parsing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgroup_reps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcitations_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mjournals_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mCONSOLIDATE_ITERS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mterm_whitelist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mNUM_TERMS_TO_KEEP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mSKIP_N\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      <no docstring>\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\amcga\\github\\knowknow\\knowknow\\datasources\\jstor.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     my_counter, sparse_counter\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jstor.jstor_counter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparse_counter( jstor.jstor_counter ):\n",
    "\n",
    "    def account_for(self, doc):\n",
    "\n",
    "        # year\n",
    "        self.cnt(doc['year'], 'fy', doc['doi'])\n",
    "\n",
    "        # journal\n",
    "        self.cnt(doc['journal'], 'fj', doc['doi'])\n",
    "\n",
    "        # journal year\n",
    "        self.cnt((doc['journal'], doc['year']), 'fj.fy', doc['doi'])\n",
    "\n",
    "        # constructing the tuples set :)\n",
    "        sp = doc['content'].lower() # debating lowercaseing..\n",
    "        sp = re.sub(\"[^a-zA-Z\\s]+\", \"\", sp)  # removing extraneous characters\n",
    "        sp = re.sub(\"\\s+\", \" \", sp)  # removing extra characters\n",
    "        sp = sp.strip()\n",
    "        sp = sp.split()  # splitting into words\n",
    "\n",
    "        sp = [x for x in sp if x not in self.stopwords]  # strip stopwords\n",
    "\n",
    "        # print(len(tups),c['contextPure'], \"---\", tups)\n",
    "\n",
    "        tups = set(\"-\".join(list(x)) for x in set(zip(sp[:-1], sp[1:])))  # two-word *ordered* tuples\n",
    "        tups.update(sp)  # one-word tuples\n",
    "\n",
    "        if len(self.term_whitelist):\n",
    "            tups = [x for x in tups if x in self.term_whitelist]\n",
    "\n",
    "        # just term count, in case we are using the `basic` mode\n",
    "        for t1 in tups:\n",
    "            # term\n",
    "            self.cnt((t1,), 't', doc['doi'])\n",
    "            \n",
    "            # year\n",
    "            self.cnt(doc['year'], 'fy', doc['doi'])\n",
    "\n",
    "            # journal\n",
    "            self.cnt(doc['journal'], 'fj', doc['doi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sparse_counter(\n",
    "    jstor_zip_base = \"G:/My Drive/2020 ORGANISATION/1. PROJECTS/qualitative analysis of literature/110 CITATION ANALYSIS/000 data/sociology jstor\",\n",
    "    #jstor_zip_base = \"Z:/google_drive/1. PROJECTS/qualitative analysis of literature/110 CITATION ANALYSIS/000 data/sociology jstor\",\n",
    "    output_database = 'sociology-jstor-sparse-simple',\n",
    "    RUN_EVERYTHING=False, SKIP_N = 10*5 - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will print updated statistics every 20 documents.\n",
      "Iterating over  248380 documents\n",
      "Document 0 ... 0 journals... 0 cited works... 0 authors... 0 terms used... 0 'social' terms\n",
      "Document 20 ... 11 journals... 0 cited works... 0 authors... 44882 terms used... 13 'social' terms\n",
      "Document 40 ... 20 journals... 0 cited works... 0 authors... 107982 terms used... 29 'social' terms\n",
      "Document 60 ... 24 journals... 0 cited works... 0 authors... 171168 terms used... 43 'social' terms\n",
      "Document 80 ... 27 journals... 0 cited works... 0 authors... 225654 terms used... 55 'social' terms\n",
      "Document 100 ... 28 journals... 0 cited works... 0 authors... 273704 terms used... 69 'social' terms\n",
      "Document 120 ... 31 journals... 0 cited works... 0 authors... 330656 terms used... 83 'social' terms\n",
      "Document 140 ... 33 journals... 0 cited works... 0 authors... 373597 terms used... 91 'social' terms\n",
      "Document 160 ... 34 journals... 0 cited works... 0 authors... 429571 terms used... 108 'social' terms\n",
      "Document 180 ... 34 journals... 0 cited works... 0 authors... 469394 terms used... 123 'social' terms\n",
      "Document 200 ... 36 journals... 0 cited works... 0 authors... 514134 terms used... 136 'social' terms\n",
      "Document 220 ... 39 journals... 0 cited works... 0 authors... 572984 terms used... 151 'social' terms\n",
      "Document 240 ... 40 journals... 0 cited works... 0 authors... 636632 terms used... 166 'social' terms\n",
      "Document 260 ... 42 journals... 0 cited works... 0 authors... 685877 terms used... 182 'social' terms\n",
      "Document 280 ... 42 journals... 0 cited works... 0 authors... 736823 terms used... 198 'social' terms\n",
      "Document 300 ... 42 journals... 0 cited works... 0 authors... 777533 terms used... 212 'social' terms\n",
      "Document 320 ... 42 journals... 0 cited works... 0 authors... 812825 terms used... 226 'social' terms\n",
      "Document 340 ... 42 journals... 0 cited works... 0 authors... 864483 terms used... 243 'social' terms\n",
      "Document 360 ... 42 journals... 0 cited works... 0 authors... 904754 terms used... 258 'social' terms\n",
      "Document 380 ... 42 journals... 0 cited works... 0 authors... 956215 terms used... 275 'social' terms\n",
      "Document 400 ... 42 journals... 0 cited works... 0 authors... 998573 terms used... 287 'social' terms\n",
      "Document 420 ... 42 journals... 0 cited works... 0 authors... 1042781 terms used... 303 'social' terms\n",
      "Document 440 ... 43 journals... 0 cited works... 0 authors... 1095937 terms used... 320 'social' terms\n",
      "Document 460 ... 44 journals... 0 cited works... 0 authors... 1125019 terms used... 333 'social' terms\n",
      "Document 480 ... 45 journals... 0 cited works... 0 authors... 1173023 terms used... 349 'social' terms\n",
      "Document 500 ... 45 journals... 0 cited works... 0 authors... 1211533 terms used... 363 'social' terms\n",
      "Document 520 ... 45 journals... 0 cited works... 0 authors... 1260008 terms used... 379 'social' terms\n",
      "Document 540 ... 45 journals... 0 cited works... 0 authors... 1306912 terms used... 393 'social' terms\n",
      "Document 560 ... 46 journals... 0 cited works... 0 authors... 1342080 terms used... 405 'social' terms\n",
      "Document 580 ... 46 journals... 0 cited works... 0 authors... 1374227 terms used... 417 'social' terms\n",
      "Document 600 ... 46 journals... 0 cited works... 0 authors... 1399627 terms used... 432 'social' terms\n",
      "Document 620 ... 46 journals... 0 cited works... 0 authors... 1441767 terms used... 445 'social' terms\n",
      "Document 640 ... 46 journals... 0 cited works... 0 authors... 1499861 terms used... 459 'social' terms\n",
      "Document 660 ... 46 journals... 0 cited works... 0 authors... 1528439 terms used... 472 'social' terms\n",
      "Document 680 ... 46 journals... 0 cited works... 0 authors... 1574968 terms used... 488 'social' terms\n",
      "Document 700 ... 46 journals... 0 cited works... 0 authors... 1596964 terms used... 500 'social' terms\n",
      "Document 720 ... 46 journals... 0 cited works... 0 authors... 1634506 terms used... 515 'social' terms\n",
      "Document 740 ... 46 journals... 0 cited works... 0 authors... 1669389 terms used... 527 'social' terms\n",
      "Document 760 ... 46 journals... 0 cited works... 0 authors... 1712088 terms used... 542 'social' terms\n",
      "Document 780 ... 46 journals... 0 cited works... 0 authors... 1755525 terms used... 558 'social' terms\n",
      "Document 800 ... 46 journals... 0 cited works... 0 authors... 1797536 terms used... 573 'social' terms\n",
      "Document 820 ... 46 journals... 0 cited works... 0 authors... 1838156 terms used... 586 'social' terms\n",
      "Document 840 ... 46 journals... 0 cited works... 0 authors... 1865449 terms used... 598 'social' terms\n",
      "Document 860 ... 46 journals... 0 cited works... 0 authors... 1895216 terms used... 610 'social' terms\n",
      "Document 880 ... 46 journals... 0 cited works... 0 authors... 1930539 terms used... 627 'social' terms\n",
      "Document 900 ... 46 journals... 0 cited works... 0 authors... 1963799 terms used... 643 'social' terms\n",
      "Document 920 ... 46 journals... 0 cited works... 0 authors... 1998820 terms used... 656 'social' terms\n",
      "Document 940 ... 46 journals... 0 cited works... 0 authors... 2043151 terms used... 673 'social' terms\n",
      "Document 960 ... 46 journals... 0 cited works... 0 authors... 2069339 terms used... 684 'social' terms\n",
      "Document 980 ... 46 journals... 0 cited works... 0 authors... 2114211 terms used... 701 'social' terms\n",
      "Document 1000 ... 46 journals... 0 cited works... 0 authors... 2155670 terms used... 716 'social' terms\n",
      "Document 1020 ... 46 journals... 0 cited works... 0 authors... 2190373 terms used... 729 'social' terms\n",
      "Document 1040 ... 46 journals... 0 cited works... 0 authors... 2225554 terms used... 744 'social' terms\n",
      "Document 1060 ... 46 journals... 0 cited works... 0 authors... 2257176 terms used... 756 'social' terms\n",
      "Document 1080 ... 48 journals... 0 cited works... 0 authors... 2289350 terms used... 769 'social' terms\n",
      "Document 1100 ... 48 journals... 0 cited works... 0 authors... 2328660 terms used... 784 'social' terms\n",
      "Document 1120 ... 48 journals... 0 cited works... 0 authors... 2371709 terms used... 803 'social' terms\n",
      "Document 1140 ... 48 journals... 0 cited works... 0 authors... 2407899 terms used... 818 'social' terms\n",
      "Document 1160 ... 48 journals... 0 cited works... 0 authors... 2437369 terms used... 831 'social' terms\n",
      "Document 1180 ... 48 journals... 0 cited works... 0 authors... 2481823 terms used... 847 'social' terms\n",
      "Document 1200 ... 48 journals... 0 cited works... 0 authors... 2522052 terms used... 862 'social' terms\n",
      "Document 1220 ... 48 journals... 0 cited works... 0 authors... 2559365 terms used... 876 'social' terms\n",
      "Document 1240 ... 48 journals... 0 cited works... 0 authors... 2586978 terms used... 888 'social' terms\n",
      "Document 1260 ... 48 journals... 0 cited works... 0 authors... 2622048 terms used... 904 'social' terms\n",
      "Document 1280 ... 48 journals... 0 cited works... 0 authors... 2666267 terms used... 921 'social' terms\n",
      "Document 1300 ... 48 journals... 0 cited works... 0 authors... 2696471 terms used... 933 'social' terms\n",
      "Document 1320 ... 48 journals... 0 cited works... 0 authors... 2727795 terms used... 947 'social' terms\n"
     ]
    }
   ],
   "source": [
    "c.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default-database-name'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.output_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2740481"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c.doc['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file not found. Looking for entry in Harvard Dataverse...\n",
      "No entry found in Harvard dataverse.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Create new folder with name `sociology-jstor-sparse-simple`?:  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variable sociology-jstor-sparse-simple/_attributes from disk\n",
      "loading variable sociology-jstor-sparse-simple/groups from disk\n"
     ]
    }
   ],
   "source": [
    "c.output_database = 'sociology-jstor-sparse-simple'\n",
    "c.save_counters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first filter based on number of times each term was mentioned\n",
    "\n",
    "We want this to be as wide a net we can stand for the next filtering processes.\n",
    "I cannot keep track of yearly counts of all terms, or even simple term counts (at least, not without dynamic consolidation), because of RAM limitations.\n",
    "Remember that I'm keeping track of all words, but also all two-word tuples!\n",
    "So this first stage is only using 1/10 of the documents (see above, SKIP_N)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--At this point, subsetting the data now that we have a terms list will not help our memory issue.-->\n",
    "The term-term coocurrence network uses N^2 integers, which with 1M terms is 1M^2 = 1TB of memory.\n",
    "If we can limit to ~30,000 terms, approximately the working vocabulary of an adult, this would fit in 1GB of memory.\n",
    "We can filter by term *dynamics* instead of just relying on .\n",
    "We can also limit the 1-tuples and 2-tuples independently, reserving 15,000 terms for each.\n",
    "2-tuples currently make up the majority of our counts, but are not inherently more important than 1-tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowknow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variable sociology-jstor-sparse-simple/_attributes from disk\n",
      "loading variable sociology-jstor-sparse-simple/groups from disk\n"
     ]
    }
   ],
   "source": [
    "c = Dataset('sociology-jstor-sparse-simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(t(t='social'), 954),\n",
       " (t(t='globalization-market'), 2),\n",
       " (t(t='beginning-transformation'), 1),\n",
       " (t(t='ethnic-problems'), 1),\n",
       " (t(t='andrzej-rychard'), 1),\n",
       " (t(t='based-strength'), 2),\n",
       " (t(t='greatest-contribution'), 4),\n",
       " (t(t='partially-explained'), 6),\n",
       " (t(t='exactly-differences'), 1),\n",
       " (t(t='year'), 591)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = c.by('t').docs\n",
    "list(cc.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_N = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variable sociology-jstor-sparse-simple/doc ___ fy from disk\n"
     ]
    }
   ],
   "source": [
    "ndocs = sum(c.by('fy').docs.values())\n",
    "#cutoff_bot = 0.001 # if present in less than 1/1000 of the documents, discard\n",
    "#cutoff_count = 2 # if present in less than 2 documents, discard\n",
    "#cutoff_top = 0.500 # if present in more than 50% of documents, discard\n",
    "\n",
    "assert( not any( c>ndocs for c in cc.values() ) )\n",
    "\n",
    "#ndoc_bot = cutoff_bot*ndocs\n",
    "#ndoc_bot = max(cutoff_count, ndoc_bot)\n",
    "\n",
    "#terms_to_keep = [t for t,c in c.doc['t'].items() if ndoc_bot <= c <= cutoff_top*ndocs]\n",
    "\n",
    "tups1 = sorted(\n",
    "    [x for x in cc if '-' not in x[0]], \n",
    "    key=lambda x:cc[x]\n",
    ")[ -target_N: ]\n",
    "\n",
    "tups2 = sorted(\n",
    "    [x for x in cc if '-' in x[0]], \n",
    "    key=lambda x:cc[x]\n",
    ")[ -target_N: ]\n",
    "\n",
    "terms_to_keep = tups1 + tups2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_to_keep = [x[0] for x in terms_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['indicate', 'one', 'despite', 'recent', 'london-routledge', 'descriptive-statistics', 'ed', 'sociological-theory', 'social-system', 'social-scientists', 'order', 'policy', 'processes', 'article', 'per-cent', 'source', 'sociology-social', 'compared', 'decision-making', 'great-deal', 'high-levels', 'seems', 'cultural', 'j-c', 'seen', 'percent-percent', 'persons', 'among', 'may-seem', 'factor-analysis', 'basis', 'york-mcgrawhill', 'provide', 'two-groups', 'government', 'behavior', 'changing', 'reported-table', 'another-way', 'c-j', 'social-mobility', 'oaks-ca', 'yale-university', 'much-higher', 'provides', 'must', 'literature', 'sample-size', 'institute-social', 'higher-education']\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "print(sample(terms_to_keep, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing the number of terms from 2,740,481 to 1,000.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reducing the number of terms from {len(cc):0,} to {len(terms_to_keep):0,}.\")\n",
    "#print(f\"To those terms present in a minimum of {ndoc_bot} docs, and maximum of {cutoff_top*ndocs} docs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('terms.pickle', 'wb') as outf:\n",
    "    pickle.dump(terms_to_keep,outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store terms_to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recount with fuller detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowknow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowknow.datasources import jstor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class full_counter( jstor.jstor_counter ):\n",
    "\n",
    "    def account_for(self, doc):\n",
    "\n",
    "        # year\n",
    "        self.cnt(doc['year'], 'fy', doc['doi'])\n",
    "\n",
    "        # journal\n",
    "        self.cnt(doc['journal'], 'fj', doc['doi'])\n",
    "\n",
    "        # journal year\n",
    "        self.cnt((doc['journal'], doc['year']), 'fj.fy', doc['doi'])\n",
    "\n",
    "        # constructing the tuples set :)\n",
    "        \n",
    "        sp = doc['content'].lower() # debating lowercaseing..\n",
    "        sp = re.sub(\"[^a-zA-Z\\s]+\", \"\", sp)  # removing extraneous characters\n",
    "        sp = re.sub(\"\\s+\", \" \", sp)  # removing extra characters\n",
    "        sp = sp.strip()\n",
    "        sp = sp.split()  # splitting into words\n",
    "\n",
    "        sp = [x for x in sp if x not in self.stopwords]  # strip stopwords\n",
    "\n",
    "        # print(len(tups),c['contextPure'], \"---\", tups)\n",
    "\n",
    "        # keep everything in order\n",
    "        tups = [\"-\".join(list(x)) for x in zip(sp[:-1], sp[1:])]  # two-word *ordered* tuples\n",
    "        tups = [ sp[i//2] if i%2==0 else tups[(i-1)//2] for i in range(2*len(sp)-1) ]\n",
    "\n",
    "        if len(self.term_whitelist):\n",
    "            tups = [x for x in tups if x in self.term_whitelist]\n",
    "\n",
    "        # just term count, in case we are using the `basic` mode\n",
    "        for i1, t1 in enumerate(tups):\n",
    "            # term\n",
    "            self.cnt((t1,), 't', doc['doi'])\n",
    "\n",
    "            if self.RUN_EVERYTHING:\n",
    "                # term year\n",
    "                self.cnt((doc['year'], t1), 'fy.t', doc['doi'])\n",
    "\n",
    "                # term journal\n",
    "                self.cnt((doc['journal'], t1), 'fj.t', doc['doi'])\n",
    "                \"\"\"\n",
    "                # author loop\n",
    "                for a in doc['authors']:\n",
    "                    # term author\n",
    "                    self.cnt((a, t1), 'fa.t', doc['doi'])\n",
    "                \"\"\"\n",
    "\n",
    "                for t2 in tups[i1+1:i1+1+5]:\n",
    "                    self.cnt((t1, t2), 't1.t2', doc['doi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('terms.pickle', 'rb') as inf:\n",
    "    terms_to_keep = pickle.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = full_counter(\n",
    "    jstor_zip_base = \"G:/My Drive/2020 ORGANISATION/1. PROJECTS/qualitative analysis of literature/110 CITATION ANALYSIS/000 data/sociology jstor\",\n",
    "    output_database = 'sociology-jstor-all',\n",
    "    RUN_EVERYTHING=True, complex_parsing=False,\n",
    "    term_whitelist=terms_to_keep,\n",
    "    SKIP_N=9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will print updated statistics every 100 documents.\n",
      "Iterating over  248380 documents\n",
      "Document 0 ... 0 journals... 0 cited works... 0 authors... 0 terms used... 0 'social' terms\n",
      "Document 100 ... 29 journals... 0 cited works... 0 authors... 1000 terms used... 74 'social' terms\n",
      "Document 200 ... 38 journals... 0 cited works... 0 authors... 1000 terms used... 150 'social' terms\n",
      "Document 300 ... 41 journals... 0 cited works... 0 authors... 1000 terms used... 218 'social' terms\n",
      "Document 400 ... 42 journals... 0 cited works... 0 authors... 1000 terms used... 286 'social' terms\n",
      "Document 500 ... 44 journals... 0 cited works... 0 authors... 1000 terms used... 357 'social' terms\n",
      "Document 600 ... 44 journals... 0 cited works... 0 authors... 1000 terms used... 431 'social' terms\n",
      "Document 700 ... 44 journals... 0 cited works... 0 authors... 1000 terms used... 502 'social' terms\n",
      "Document 800 ... 44 journals... 0 cited works... 0 authors... 1000 terms used... 570 'social' terms\n",
      "Document 900 ... 45 journals... 0 cited works... 0 authors... 1000 terms used... 645 'social' terms\n",
      "Document 1000 ... 45 journals... 0 cited works... 0 authors... 1000 terms used... 724 'social' terms\n",
      "Document 1100 ... 45 journals... 0 cited works... 0 authors... 1000 terms used... 802 'social' terms\n",
      "Document 1200 ... 45 journals... 0 cited works... 0 authors... 1000 terms used... 876 'social' terms\n",
      "Document 1300 ... 46 journals... 0 cited works... 0 authors... 1000 terms used... 948 'social' terms\n",
      "Document 1400 ... 46 journals... 0 cited works... 0 authors... 1000 terms used... 1021 'social' terms\n",
      "Document 1500 ... 47 journals... 0 cited works... 0 authors... 1000 terms used... 1098 'social' terms\n",
      "Document 1600 ... 47 journals... 0 cited works... 0 authors... 1000 terms used... 1163 'social' terms\n",
      "Document 1700 ... 47 journals... 0 cited works... 0 authors... 1000 terms used... 1233 'social' terms\n",
      "Document 1800 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 1310 'social' terms\n",
      "Document 1900 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 1379 'social' terms\n",
      "Document 2000 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 1455 'social' terms\n",
      "Document 2100 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 1523 'social' terms\n",
      "Document 2200 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 1590 'social' terms\n",
      "Document 2300 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 1660 'social' terms\n",
      "Document 2400 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 1744 'social' terms\n",
      "Document 2500 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 1818 'social' terms\n",
      "Document 2600 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 1893 'social' terms\n",
      "Document 2700 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 1968 'social' terms\n",
      "Document 2800 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 2035 'social' terms\n",
      "Document 2900 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 2107 'social' terms\n",
      "Document 3000 ... 48 journals... 0 cited works... 0 authors... 1000 terms used... 2180 'social' terms\n",
      "Document 3100 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 2251 'social' terms\n",
      "Document 3200 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 2330 'social' terms\n",
      "Document 3300 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 2404 'social' terms\n",
      "Document 3400 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 2469 'social' terms\n",
      "Document 3500 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 2543 'social' terms\n",
      "Document 3600 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 2615 'social' terms\n",
      "Document 3700 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 2693 'social' terms\n",
      "Document 3800 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 2774 'social' terms\n",
      "Document 3900 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 2842 'social' terms\n",
      "Document 4000 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 2919 'social' terms\n",
      "Document 4100 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 2986 'social' terms\n",
      "Document 4200 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3055 'social' terms\n",
      "Document 4300 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3136 'social' terms\n",
      "Document 4400 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3208 'social' terms\n",
      "Document 4500 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3281 'social' terms\n",
      "Document 4600 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3358 'social' terms\n",
      "Document 4700 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3436 'social' terms\n",
      "Document 4800 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3503 'social' terms\n",
      "Document 4900 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3577 'social' terms\n",
      "Document 5000 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3651 'social' terms\n",
      "Document 5100 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3725 'social' terms\n",
      "Document 5200 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3801 'social' terms\n",
      "Document 5300 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3871 'social' terms\n",
      "Document 5400 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 3944 'social' terms\n",
      "Document 5500 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4026 'social' terms\n",
      "Document 5600 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4098 'social' terms\n",
      "Document 5700 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4174 'social' terms\n",
      "Document 5800 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4243 'social' terms\n",
      "Document 5900 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4314 'social' terms\n",
      "Document 6000 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4386 'social' terms\n",
      "Document 6100 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4456 'social' terms\n",
      "Document 6200 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4525 'social' terms\n",
      "Document 6300 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4598 'social' terms\n",
      "Document 6400 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4669 'social' terms\n",
      "Document 6500 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4738 'social' terms\n",
      "Document 6600 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4810 'social' terms\n",
      "Document 6700 ... 49 journals... 0 cited works... 0 authors... 1000 terms used... 4883 'social' terms\n"
     ]
    }
   ],
   "source": [
    "c2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745670"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c2.doc['t1.t2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c2.doc['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('next', 'simply'),\n",
       " ('years-ago', 'resources'),\n",
       " ('social-forces', 'negative-effect'),\n",
       " ('socioeconomic-status', 'course'),\n",
       " ('history', 'may-lead'),\n",
       " ('variable', 'effect'),\n",
       " ('following', 'appear'),\n",
       " ('independent-variables', 'remain'),\n",
       " ('across', 'per-capita'),\n",
       " ('relationships', 'asked')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(list(c2.doc['t1.t2']), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variable sociology-jstor-all/_attributes from disk\n",
      "loading variable sociology-jstor-all/groups from disk\n"
     ]
    }
   ],
   "source": [
    "c2.save_counters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# older and slower sentence-based cooccurrence method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class full_counter( jstor.jstor_counter ):\n",
    "\n",
    "    def account_for(self, doc):\n",
    "\n",
    "        # year\n",
    "        self.cnt(doc['year'], 'fy', doc['doi'])\n",
    "\n",
    "        # journal\n",
    "        self.cnt(doc['journal'], 'fj', doc['doi'])\n",
    "\n",
    "        # journal year\n",
    "        self.cnt((doc['journal'], doc['year']), 'fj.fy', doc['doi'])\n",
    "\n",
    "        # constructing the tuples set :)\n",
    "        \n",
    "        for sent in nlp(doc['content']).sents:\n",
    "            sent = str(sent)\n",
    "            \n",
    "            sp = sent.lower() # debating lowercaseing..\n",
    "            sp = re.sub(\"[^a-zA-Z\\s]+\", \"\", sp)  # removing extraneous characters\n",
    "            sp = re.sub(\"\\s+\", \" \", sp)  # removing extra characters\n",
    "            sp = sp.strip()\n",
    "            sp = sp.split()  # splitting into words\n",
    "\n",
    "            sp = [x for x in sp if x not in self.stopwords]  # strip stopwords\n",
    "\n",
    "            # print(len(tups),c['contextPure'], \"---\", tups)\n",
    "\n",
    "            tups = set(\"-\".join(list(x)) for x in set(zip(sp[:-1], sp[1:])))  # two-word *ordered* tuples\n",
    "            tups.update(sp)  # one-word tuples\n",
    "\n",
    "            if len(self.term_whitelist):\n",
    "                tups = [x for x in tups if x in self.term_whitelist]\n",
    "\n",
    "            # just term count, in case we are using the `basic` mode\n",
    "            for t1 in tups:\n",
    "                # term\n",
    "                self.cnt((t1,), 't', doc['doi'])\n",
    "\n",
    "                if self.RUN_EVERYTHING:\n",
    "                    # term year\n",
    "                    self.cnt((doc['year'], t1), 'fy.t', doc['doi'])\n",
    "\n",
    "                    # term journal\n",
    "                    self.cnt((doc['journal'], t1), 'fj.t', doc['doi'])\n",
    "\n",
    "                    if False:\n",
    "                        # author loop\n",
    "                        for a in doc['authors']:\n",
    "                            # term author\n",
    "                            self.cnt((a, t1), 'fa.t', doc['doi'])\n",
    "\n",
    "                    if len(self.term_whitelist):  # really don't want to do this too early. wait until it's narrowed down to the 5k\n",
    "                        # term term...\n",
    "                        for t2 in tups:\n",
    "                            # if they intersect each other, continue...\n",
    "                            #if len(set(t1).intersection(set(t2))) >= min(len(t1), len(t2)):\n",
    "                            #    continue\n",
    "\n",
    "                            # term term\n",
    "                            self.cnt((t1, t2), 't1.t2', doc['doi'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (qualitative analysis of literature)",
   "language": "python",
   "name": "pycharm-b9c7981b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
